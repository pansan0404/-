\documentclass[a4paper,autodetect-engine,ja=standard,9pt]{bxjsarticle}
% --------------
% パッケージ
% --------------
\usepackage{amsmath}                  % 数式環境のサポート
\usepackage{amsfonts}                 % 数学フォント
\usepackage{caption}                  % 図表キャプションの設定
\usepackage[symbol,hang,flushmargin]{footmisc} % 脚注記号とマージン調整
\renewcommand{\thefootnote}{\fnsymbol{footnote}} % 脚注を記号に
\setcounter{footnote}{0}
\usepackage[dvipdfmx]{graphicx}       % 画像取り込み (dvipdfmx ドライバ)
\usepackage{grffile}                  % 拡張ファイル名の対応
\usepackage{lipsum}                   % ダミーテキスト
\usepackage[numbers]{natbib}          % 数値型引用
% \usepackage{stfloats}                 % figure* を [b]（bottom）に対応させる
\usepackage{dblfloatfix}
% \usepackage[font=scriptsize]{subfig}  % サブ図
\usepackage{subcaption}               % サブキャプション
\usepackage{titlesec}                 % セクション書式の制御
\usepackage{url}                      % URL の表示
% フォント設定（ローカル環境用、XeLaTeXの場合のみ）
% 本文：明朝体、見出し：ゴシック体
\ifxetex
  \usepackage{fontspec}
  \usepackage{xeCJK}
  % 本文用の明朝体
  \setCJKmainfont{Noto Serif JP}
  % 見出し用のゴシック体（bxjsarticleが自動的に見出しに適用）
  \setCJKsansfont{Hiragino Kaku Gothic ProN}
  \setCJKmonofont{Hiragino Kaku Gothic ProN}
\fi

% \usepackage[dvipdfmx]{graphicx}
% \usepackage[dvipdfmx]{color}

% ここからコピペ: 画像と色設定
\usepackage{graphicx}    % 画像取り込み
\usepackage{color}       % 色指定

\usepackage{multirow}    % 表中の複数行セル

\graphicspath{images}    % 画像パス設定

% XeLaTeXでは不要（UTF-8を直接扱える）
% \usepackage[utf8]{inputenc} % 入力エンコーディング
% \usepackage[T1]{fontenc}    % 出力エンコーディング
\usepackage{booktabs}       % 表の罫線
\usepackage{graphicx}       % 重複読み込み（意図的）

\pagestyle{empty}           % ヘッダー・フッターなし

\usepackage{bm}             % 太字数学記号

% 6pt×行送り6pt のキャプション用フォントを定義
\DeclareCaptionFont{sixpt}{\fontsize{7pt}{0pt}\selectfont}

% サブ図キャプションを
%  ・ラベルは太字（labelfont=bf）
%  ・本文（説明文）はsixpt
%  ・中央揃え、1行でも中央寄せを効かせる
\captionsetup[subfigure]{
  labelfont={bf,sixpt},
  textfont=sixpt,
  justification=centering,
  singlelinecheck=false,
  belowskip=0pt    % キャプション下の余白を 2pt に
}
\captionsetup[figure]{
    belowskip=0pt
}

\captionsetup[table]{
  position=top,    % キャプションを表の上に
}

\usepackage{booktabs}
\usepackage{siunitx}        % 数値の単位とフォーマット（S列タイプ用）
\usepackage{colortbl}   % \rowcolor, \rowcolors
\usepackage{xcolor}
\definecolor{highlight}{HTML}{FFE5CC}  % お好みのハイライト色

% --------------
% レイアウト
% --------------
\setpagelayout*{top=40truemm,bottom=35truemm,left=30truemm,right=30truemm}

% 独自コマンド例: 均等割り付け
\newcommand\kintouwari[2]{{%
  \setkanjiskip{\fill}%
  \makebox[#1\zw][s]{#2}}}

% カラム間隔設定
\setlength{\columnsep}{20truept}
% 縦は49行であり，14truept が 1行 の高さ

% セクション書式設定
% セクション書式設定（見出しをゴシック体に）
\titleformat{\section}
  {\sffamily\fontsize{18\ascpt}{18truept}\bfseries}
  {\thesection}{1em}{}
\titleformat{\subsection}
  {\sffamily\fontsize{14\ascpt}{14truept}\bfseries}
  {\thesubsection}{1em}{}
% ★ subsubsection の設定を変更 ★
\titleformat{\subsubsection}
  {\sffamily\fontsize{12\ascpt}{12truept}\bfseries}
  {}          % 番号（空）
  {0pt}       % ★ ここを 0pt にする ★
  {}





% --------------
% Document
% --------------
\begin{document}

  \begin{center}
    \vspace{14truept}
    {\sffamily\bfseries  
    % ! タイトル -----------------------------------
    \fontsize{16\ascpt}{25\ascpt}\selectfont
    ドローンを用いた3次元再構成における\\テキスト指示型編集技術の開発

    % ! --------------------------------------------
    }
    \par
    \vspace{40truept}

    % ──────────────── 著者ブロック ────────────────
    {\fontsize{14\ascpt}{10.5\ascpt}\selectfont
      \begin{tabular}{@{}ccc@{}}
        菊地佑太 \\
      \end{tabular}
    }

    \end{center}

    \vspace{50truept}

 \begin{center}

   {\sffamily\bfseries\fontsize{11\ascpt}{10.5\ascpt}\selectfont
      \begin{tabular}{@{}ccc@{}}
        内容梗概 \\
      \end{tabular}
    }
 \end{center}

\vspace{25truept}
    

% 縦49行に合わせる
\fontsize{11\ascpt}{16truept}\selectfont % 12pt に変更
\setlength{\baselineskip}{20pt}% デフォルト12pt。行送りを16ptに



%-----------------------------------
% セクション: アブストラクト
%-----------------------------------



環境の画像から自由視点画像を得る技術は，近年のAIの発達によって急激に発展している．
3D Gaussian Splatting（3DGS）はその代表的な例である．
ドローンを用いて屋外撮影をする場合の固有の課題が発生するが，
それらに対する先行研究もある．
例えば，時刻とともに人や物の位置が変化してしまうため，3次元再構成が困難になるが
DroneSplatではそれに対する対応が行われている．



本研究では映り込んだ不要物体を除去することを考える．
提案手法では，テキストで除去する物体を指定することで，自由視点画像から所望の物体を除去することができる．
これにより，ドローン画像の3次元再構成の活用がしやすくなる．
これを実現するために，学習用画像から不要な物体をCLIP等のマルチモーダル画像分類器で同定し，学習に使用する画像から削除することで，再構成させる自由視点画像の最適化を試みる．


\footnotetext{東北大学大学院情報科学研究科　応用情報科学専攻　学位論文, C4IM4010}

\newpage
\tableofcontents

\newpage
\section{はじめに}
\subsection{本研究の概要}

環境の画像から自由視点画像を得る技術は，近年のAIの発達によって急激に発展している．
3D Gaussian Splatting（3DGS） \cite{kerbl3Dgaussians}はその代表的な例である．
ドローンを用いて屋外撮影をする場合の固有の課題が発生するが，
それらに対する先行研究もある．
例えば，時刻とともに人や物の位置が変化してしまうため，3次元再構成が困難になるが（図1-a），
DroneSplat\cite{tang2025dronesplat3dgaussiansplatting}ではそれに対する対応が行われている（図1-b）．





本研究では映り込んだ不要物体を除去することを考える．
提案手法では，テキストで除去する物体を指定することで，自由視点画像から所望の物体を除去することができる．
これにより，ドローン画像の3次元再構成の活用がしやすくなる．
これを実現するために，学習用画像から不要な物体をCLIP\cite{DBLP:journals/corr/abs-2103-00020}等のマルチモーダル画像分類器で同定し，学習に使用する画像から削除することで（図2），再構成させる自由視点画像の最適化を試みる．

\subsection{本研究の構成}
本論文は次のように構成される．
第一章では本研究の概要を説明した．
第二章では主要な3次元再構成に触れつつ，現状の課題を述べる．
第三章では提案手法を説明する．不要物を同定するアルゴリズムと，拡散モデルによる削除部の補完を行う手法を説明する．
第四章では評価実験と考察を行う．


\newpage
\section{研究背景}
\subsection{関連研究}
\subsubsection{3次元再構成技術}
%SfMとかについて
3次元再構成とは，3次元空間における物体の形状や位置を再構成する技術である．
SfM（Structure-from-Motion：運動復元）\cite{snavely2006photo}はその代表的な例である．
SfMは，同一シーンを異なる視点から撮影した複数の画像から，3次元空間におけるシーンの構造（Structure）と各画像を撮影したカメラの位置・姿勢（Motion）を同時に推定する技術である．
処理の流れとしては，まず各画像から特徴点（SIFTやORBなどの特徴記述子）を検出し，異なる画像間で対応する特徴点をマッチングする．
次に，対応点の情報を用いてカメラの内部パラメータと外部パラメータ（位置・姿勢）を推定し，三角測量により3次元点群を復元する．
最後に，バンドル調整（Bundle Adjustment）と呼ばれる最適化手法により，再投影誤差を最小化することで，カメラパラメータと3次元構造を同時に精密化する．
SfMは，特別な計測機器を必要とせず，一般的なカメラで撮影した画像のみから3次元モデルを構築できる点が大きな利点であり，フォトグラメトリやデジタルアーカイブ，地図作成などの幅広い分野で活用されている．

%NeRFについて
そのほかにも，ニューラルネットワークを用いて3次元空間を表現する手法がある．
NeRF\cite{mildenhall2020nerfrepresentingscenesneural}は，2020年にMildenhallらによって提案された，ニューラルネットワークを用いてシーンを連続的な関数として表現する技術である．
同一シーンを異なる視点から撮影した複数の画像とカメラパラメータを用いて学習し，ボリュームレンダリングにより任意の視点から高品質な自由視点画像を生成することができる．
NeRFの主な利点は，従来の点群ベースの手法と比較して，3次元空間を連続的な関数として表現することで，細部まで高品質な画像を生成できる点である．
一方で，レンダリング時に各ピクセルごとにニューラルネットワークの推論が必要となるため，レンダリング速度が非常に遅く，リアルタイムでの自由視点ナビゲーションが困難であるという課題がある．

%3dgsについて
このレンダリングの遅さを解消したのが，2023年に発表されたのがKerblらによって提案された3D Gaussian Splatting (3DGS) \cite{kerbl3Dgaussians} である．
学習を進めながら生成の品質を高める点ではNeRFと同一であるが，3次元空間を3次元ガウス分布の集合として表現することが特徴である．
各ガウス分布は，位置，共分散行列（形状と向き），不透明度，そして球状調和関数に基づく色情報をパラメータとして持つ．
ポイントベースの$\alpha$（アルファ）ブレンディングとNeRFスタイルのボリュームレンダリングは，本質的に同じ画像生成モデルを共有している．
具体的には，ある光線（レイ）に沿った色$C$は，以下のボリュームレンダリングの式で与えられる：
\begin{equation}
C = \sum_{i=1}^{N} T_i (1 - \exp(-\sigma_i \delta_i)) c_i \quad \text{ここで} \quad T_i = \exp\left(-\sum_{j=1}^{i-1} \sigma_j \delta_j\right)
\end{equation}
ここで，密度$\sigma$，透過率$T$，および色$c$のサンプルが，間隔$\delta_i$で光線に沿って取得される．
これは次のように書き換えることができる：
\begin{equation}
C = \sum_{i=1}^{N} T_i \alpha_i c_i
\end{equation}
ただし，$\alpha_i = (1 - \exp(-\sigma_i \delta_i))$および$T_i = \prod_{j=1}^{i-1}(1 - \alpha_j)$である．
典型的なニューラルポイントベースのアプローチは，ピクセルに重なる$N$個の順序付けられた点をブレンディングすることで，ピクセルの色$C$を計算する：
\begin{equation}
C = \sum_{i \in N} c_i \alpha_i \prod_{j=1}^{i-1}(1 - \alpha_j)
\end{equation}
ここで，$c_i$は各点の色であり，$\alpha_i$は学習された「点ごとの不透明度」に，共分散$\Sigma$を持つ2次元ガウス関数を評価して得られる値を掛け合わせることで求められる．



自由視点画像を生成する際，これらの3Dガウス分布をカメラ平面にスプラッティング（射影）し，ハードウェアが高速に処理できるラスタライズ技術を利用してピクセル単位の色を合成する．
これにより，NeRFと比較して画質を維持しつつ，学習時間およびレンダリング速度を大幅に短縮し，リアルタイムでの自由視点ナビゲーションを可能にした \cite{kerbl3Dgaussians}．
本研究の提案手法も，この高速な3DGSを基盤技術として採用している．
\subsubsection{セマンティックセグメンテーション}
セマンティックセグメンテーションは，画像の各ピクセルをなんらか意味を持った領域に分割する技術のことである．
一つの画像に対して一つのラベルを付与する画像分類問題や，画像内の物体を認識し，矩形で過酷む物体検出と比べると，セマンティックセグメンテーションは画像中のピクセルに対してラベルを付与することで，より細かい粒度での物体の分割を行うことができる（図\ref{fig:concept}）．

SAM2\cite{ravi2024sam2}はセマンティックセグメンテーションの代表的な例である．
SAM2は，従来のセマンティックセグメンテーション手法が特定の物体クラスに限定されていたり，動画シーケンスへの対応が困難であったりした課題を克服した画期的な手法である．
SAM2の最大の特徴は，大規模データセットで学習された汎用的なセグメンテーションモデルを持ち，事前に学習した物体クラス以外の物体もセグメンテーションできる点である．
さらに，画像だけでなく動画シーケンスにも対応し，時系列情報を活用することで，より一貫性のあるセグメンテーション結果を生成することができる．
また，ユーザーからの点や矩形，テキストなどの多様な入力形式を受け付けることができる点も，従来手法と比較して大きな進歩であった．


\begin{figure}[htbp]
  \centering
  \begin{subfigure}[t]{0.32\columnwidth}
    \centering
    \includegraphics[width=\linewidth]{img-for-paper/fig_concept_classification.png}
    \caption{画像分類\\画像全体を見て「人」であると判断している}
    \label{fig:classification}
  \end{subfigure}\hfill
  \begin{subfigure}[t]{0.32\columnwidth}
    \centering
    \includegraphics[width=\linewidth]{img-for-paper/fig_concept_detection.jpg}
    \caption{物体検出\\画像内の物体を矩形で囲んで認識し，\\それぞれの物体の位置とクラスを特定している}
    \label{fig:detection}
  \end{subfigure}\hfill
  \begin{subfigure}[t]{0.32\columnwidth}
    \centering
    \includegraphics[width=\linewidth]{img-for-paper/fig_concept_segmentation.jpg}
    \caption{セマンティックセグメンテーション\\画像の各ピクセルに対してラベルを付与することで，\\より細かい粒度での物体の分割を行うことができる}
    \label{fig:segmentation}
  \end{subfigure}
  \vspace{1ex}
  \caption{コンピュータビジョンタスクの比較}
  \label{fig:concept}
\end{figure}

\subsubsection{映り込みに対応した自由視点画像生成技術}
Tang らによって提案されたDroneSplat\cite{tang2025dronesplat3dgaussiansplatting} は，ドローンを用いた大規模な屋外環境における動的物体への耐性を高めた3DGS\cite{kerbl3Dgaussians}の拡張手法である．本手法では，Segment Anything Model v2（SAM2）\cite{ravi2024sam2} を用いて各視点の学習用画像のセグメントを得る．学習過程において，動いているセグメントを段階的に学習から除外することで，動的な不要物体を考慮しない再構成が可能となる．評価実験では，従来の3DGS に対し，ドローン撮影時の再構成精度および視点合成品質の両面で有意な改善を示しつつ，GPU 上でのリアルタイムレンダリング性能も維持できることが報告されている．
\subsection{現状の課題}

\newpage
\section{提案手法}
\subsection{不要物同定アルゴリズム}
\subsection{拡散モデルによる削除部の補完}


\newpage
\section{評価実験と考察}
\subsection{データセット}
\subsection{学習}
\subsection{評価手法}
\subsection{結果}

\newpage
\section{おわりに}
おわりにです．いったんいかに使えそうなものを避難させておくこととする．

\begin{table}[b]
  \centering
  \caption{Simingshanデータセットにおける各手法の性能比較}
  \rowcolors{3}{white}{gray!10}  % 3行目以降、交互に灰背景
  \begin{tabular}{l
                  S[table-format=2.2]
                  S[table-format=1.3]
                  S[table-format=1.3]}
    \toprule
    Method
      & \multicolumn{3}{c}{Simingshan} \\
    \cmidrule(lr){2-4}
      & {PSNR\(\uparrow\)} & {SSIM\(\uparrow\)} & {LPIPS\(\downarrow\)} \\
    \midrule
    NeRF\cite{mildenhall2020nerfrepresentingscenesneural}                 & 19.07 & 0.417 & 0.267 \\
    3DGS\cite{kerbl3Dgaussians}          & 19.68 & 0.476 & 0.254 \\
    DroneSplat\cite{tang2025dronesplat3dgaussiansplatting}                  & 22.76 & 0.759 & 0.152 \\
    Ours                        & 22.35 & 0.744 & 0.174 \\
    \bottomrule
  \end{tabular}
  \label{tab:metrics}
\end{table}


\begin{figure}[b]     % !b でコラム下部
  \centering
  \begin{subfigure}[t]{0.48\columnwidth}
    \centering
    \includegraphics[width=\linewidth]{img-for-paper/fig1_a.jpg}
    \caption{3DGS\cite{kerbl3Dgaussians}で作成\\車が動いている場面を表現できない}
    \label{fig:3dgs}
  \end{subfigure}\hfill
  \begin{subfigure}[t]{0.48\columnwidth}
    \centering
    \includegraphics[width=\linewidth]{img-for-paper/fig1_b.jpg}
    \caption{DroneSplat\cite{tang2025dronesplat3dgaussiansplatting}で生成\\動体を無視して表現できる}
    \label{fig:prior}
  \end{subfigure}
  \vspace{1ex}
  \caption{動的シーンにおける自由視点画像生成の例}
  \label{fig:comparison}
\end{figure}
\newpage


\subsection{結論}
\subsection{今後の課題}
課題は．．．．


% 手動で参考文献見出しを配置
\begingroup
  % リスト本体を 8 pt に設定（デフォルト8,10）小さくしたかったら変える
  % \fontsize{8\ascpt}{8truept}\selectfont
  \bibliographystyle{unsrt}
  \bibliography{references}
\endgroup



\end{document}
